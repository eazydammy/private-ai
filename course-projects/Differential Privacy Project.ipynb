{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Copy of Differential Privacy Project.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eazydammy/private-ai/blob/master/course-projects/Differential%20Privacy%20Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnKMy5hdXPKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install PySyft\n",
        "!pip install syft\n",
        "\n",
        "# import required libraries\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Subset\n",
        "from torchvision import datasets, transforms\n",
        "from syft.frameworks.torch.differential_privacy import pate\n",
        "\n",
        "# set training device as GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZZYCM1OXPKJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import datasets and apply transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "test_data = datasets.MNIST(root='./data', train=False, download=True, transform=transform)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNH218WkXPKN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define function to split training data into sub-datasets for a number of teachers\n",
        "# returns nt sub-datasets to train the each teacher model\n",
        "# TODO: split into train and test \n",
        "def split_train_data(train_data, num_teachers):\n",
        "    teacher_loaders = []\n",
        "    p, q = divmod(len(train_data), num_teachers)\n",
        "    #split_indices = list((train_data[i * p + min(i, q):(i + 1) * p + min(i + 1, q)] for i in range(num_teachers)))\n",
        "    split_indices = list(range((i * p + min(i, q)) , ((i + 1) * p + min(i+1, q))) for i in range(num_teachers))\n",
        "    for j in range(len(split_indices)):\n",
        "        subset_j = Subset(train_data, split_indices[j])\n",
        "        loader_j = torch.utils.data.DataLoader(subset_j, batch_size=64, shuffle=True)\n",
        "        teacher_loaders.append(loader_j)\n",
        "    return teacher_loaders"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEDk1ecqXPKP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define function to take a chunk of the test data as private dataset\n",
        "# returns reduced test data and private dataset in ratio: 0 < ratio < 1\n",
        "# to split reduced_test_data:private_data in 80:20, use ratio 0.8\n",
        "def split_test_data(test_data, ratio):    \n",
        "    divide = int(len(test_data) * ratio)\n",
        "    \n",
        "    reduced_indices = range(0, divide)\n",
        "    private_indices = range(divide, len(test_data))\n",
        "\n",
        "    reduced_subset = Subset(test_data, reduced_indices)\n",
        "    private_subset = Subset(test_data, private_indices)\n",
        "    \n",
        "    test_loader = torch.utils.data.DataLoader(reduced_subset, batch_size=64, shuffle=True)\n",
        "    private_loader = torch.utils.data.DataLoader(private_subset, batch_size=64, shuffle=True)\n",
        "    \n",
        "    return test_loader, private_loader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5JqrQyvXPKS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define class to build linear classifier models for each teacher\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_layers, drop_p=0.5):\n",
        "        ''' Builds a feedforward network with arbitrary hidden layers.\n",
        "        \n",
        "            Arguments\n",
        "            ---------\n",
        "            input_size: integer, size of the input layer\n",
        "            output_size: integer, size of the output layer\n",
        "            hidden_layers: list of integers, the sizes of the hidden layers\n",
        "        \n",
        "        '''\n",
        "        super().__init__()\n",
        "        # Input to a hidden layer\n",
        "        self.hidden_layers = nn.ModuleList([nn.Linear(input_size, hidden_layers[0])])\n",
        "        \n",
        "        # Add a variable number of more hidden layers\n",
        "        layer_sizes = zip(hidden_layers[:-1], hidden_layers[1:])\n",
        "        self.hidden_layers.extend([nn.Linear(h1, h2) for h1, h2 in layer_sizes])\n",
        "        self.output = nn.Linear(hidden_layers[-1], output_size)\n",
        "        self.dropout = nn.Dropout(p=drop_p)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        ''' Forward pass through the network, returns the output logits '''\n",
        "        \n",
        "        for each in self.hidden_layers:\n",
        "            x = F.relu(each(x))\n",
        "            x = self.dropout(x)\n",
        "        x = self.output(x)\n",
        "        \n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Nk2kApjXPKV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define function to train model given train and test datasets\n",
        "def train(model, trainloader, testloader, criterion, optimizer, epochs=5, print_every=50):\n",
        "    steps = 0\n",
        "    running_loss = 0\n",
        "    model.to(device)\n",
        "    for e in range(epochs):\n",
        "        model.train() # Model in training mode, grad & dropout is on\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            steps += 1\n",
        "            images.resize_(images.size()[0], 784)\n",
        "            optimizer.zero_grad()\n",
        "            output = model.forward(images)\n",
        "            loss = criterion(output, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            if steps % print_every == 0:\n",
        "                model.eval() # Model in evaluation mode, grad & dropout is off\n",
        "                with torch.no_grad():\n",
        "                    test_loss, accuracy = validation(model, testloader, criterion)\n",
        "                \n",
        "                print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
        "                      \"Training Loss: {:.3f}.. \".format(running_loss/print_every),\n",
        "                      \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
        "                      \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))\n",
        "                \n",
        "                running_loss = 0\n",
        "                model.train() # Model in training mode, grad & dropout is on"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeqGWMBuXPKX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define function to validate model using the reduced test data set\n",
        "def validation(model, testloader, criterion):\n",
        "    accuracy = 0\n",
        "    test_loss = 0\n",
        "    for images, labels in testloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        images = images.resize_(images.size()[0], 784)\n",
        "        output = model.forward(images)\n",
        "        test_loss += criterion(output, labels).item()\n",
        "        ## Calculating the accuracy \n",
        "        # Model's output is log-softmax, take exponential to get the probabilities\n",
        "        ps = torch.exp(output)\n",
        "        equality = (labels.data == ps.max(1)[1])\n",
        "        top_p, top_class = ps.topk(1, dim = 1)\n",
        "        equality = top_class == labels.view(*top_class.shape)\n",
        "        # Accuracy is number of correct predictions divided by all predictions, just take the mean\n",
        "        accuracy += equality.float().mean()\n",
        "    return test_loss, accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hw95IYoyXPKZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define function to build teacher models\n",
        "def build_teacher_models(num_teachers, teacher_dropout):\n",
        "    teacher_models = []\n",
        "    for i in range(num_teachers):\n",
        "        teacher_model = Classifier(784, 10, [512, 256, 128], drop_p = teacher_dropout)\n",
        "        teacher_models.append(teacher_model)\n",
        "    return teacher_models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjeCoaPOXPKc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define function to train teacher models\n",
        "def train_teacher_models(teacher_models, teacher_loaders, test_loader, teacher_criterion):\n",
        "    for i in range(len(teacher_models)):\n",
        "        print(\"Begin training Teacher\", i+1)\n",
        "        teacher_optimizer = optim.SGD(teacher_models[i].parameters(), lr=1e-3, momentum=0.9)\n",
        "        train(teacher_models[i], teacher_loaders[i], test_loader, teacher_criterion, teacher_optimizer, epochs=50)\n",
        "        print(\"Teacher\",i+1,\"trained successfully! \\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Q8ElPQbXPKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define function to perform PATE analysis\n",
        "def run_pate_analysis(noised_teacher_labels, raw_teacher_labels, epsilon):\n",
        "    data_dep_eps, data_ind_eps = pate.perform_analysis(teacher_preds=noised_teacher_labels, indices=raw_teacher_labels, noise_eps=epsilon, delta=1e-5)\n",
        "    print(\"Data Independent Epsilon:\", data_ind_eps)\n",
        "    print(\"Data Dependent Epsilon:\", data_dep_eps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8Fg0_wT5UJM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define function to save model training results\n",
        "def save_trained_models():\n",
        "  for i in range(len(teacher_models)): \n",
        "    torch.save(teacher_models[i].state_dict(), 'checkpoint%d.pth'%(i+1))\n",
        "    print(\"Saved model results for Teacher\", (i+1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mI4uRLvb5ot0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define function to load pre-trained models\n",
        "def load_trained_models():\n",
        "  for i in range(len(teacher_models)):\n",
        "    state_dict = torch.load('checkpoint%d.pth'%(i+1))\n",
        "    teacher_models[i].load_state_dict(state_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Afk0lIuR_s1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define function to classify private dataset\n",
        "def label_private_data(teacher_models, private_loader):\n",
        "  raw_teacher_labels = np.array([])\n",
        "  for i in range(len(teacher_models)): \n",
        "    teacher_models[i].to(device)\n",
        "    model_label = np.array([])#, dtype=np.int64).reshape(len(private_loader))\n",
        "    for images, _ in private_loader:\n",
        "        images = images.to(device)\n",
        "        images = images.resize_(images.size()[0], 784)\n",
        "        with torch.no_grad():\n",
        "          output = teacher_models[i].forward(images)\n",
        "          ps = torch.exp(output)\n",
        "        top_p, top_label = ps.topk(1, dim = 1)\n",
        "        top_label = top_label.to('cpu')\n",
        "        model_label = np.vstack((model_label, top_label)) if model_label.size else np.array(top_label)\n",
        "    #raw_teacher_labels.append(np.array(model_label))\n",
        "    raw_teacher_labels = np.hstack((raw_teacher_labels, model_label)) if raw_teacher_labels.size else np.array(model_label)\n",
        "  return raw_teacher_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLVSfvk6lyfA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define function to condense teacher labels for each image\n",
        "def condense_teacher_labels(teacher_labels):\n",
        "  condensed_labels = []\n",
        "  for teacher_label in teacher_labels:\n",
        "    label_count = np.bincount(teacher_label, minlength = 10)\n",
        "    condensed_label = np.argmax(label_count)\n",
        "    condensed_labels.append(condensed_label)\n",
        "  condensed_labels = np.array(condensed_labels)\n",
        "  return condensed_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZDoX-KBD01c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define function to add Laplacian noise scaled by epsilon value\n",
        "def add_laplacian_noise(raw_teacher_labels, epsilon):\n",
        "  noised_teacher_labels = []\n",
        "  beta = 1 / epsilon\n",
        "  for raw_teacher_label in raw_teacher_labels:\n",
        "    for i in range(len(raw_teacher_label)):\n",
        "      raw_teacher_label[i] += np.random.laplace(0, beta, 1)\n",
        "    noised_teacher_labels.append(raw_teacher_label)\n",
        "  noised_teacher_labels = np.array(noised_teacher_labels)\n",
        "  return noised_teacher_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8df1A7t2FSD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define function to create student model\n",
        "def create_student_model():\n",
        "  \n",
        "  return student_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zbm0pJ2WFZhX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define function to train student model\n",
        "def train_student_model():\n",
        "  \n",
        "  return trained_student_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wuf8UAMJFgR8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define function to validate student model\n",
        "def validate_student_model():\n",
        "  \n",
        "  return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEv-5P2UXPKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## DEFINE HYPERPARAMETERS\n",
        "num_teachers = 100\n",
        "teacher_dropout = 0.25\n",
        "teacher_criterion = nn.NLLLoss()\n",
        "epsilon = 0.1\n",
        "\n",
        "## CREATE DATALOADERS\n",
        "teacher_loaders = split_train_data(train_data, num_teachers)\n",
        "test_loader, private_loader = split_test_data(test_data, ratio=0.8)\n",
        "\n",
        "## MODELING FOR TEACHERS\n",
        "teacher_models = build_teacher_models(num_teachers, teacher_dropout)\n",
        "train_teacher_models(teacher_models, teacher_loaders, test_loader, teacher_criterion)\n",
        "\n",
        "## SAVE TRAINING RESULTS FOR TEACHERS\n",
        "save_trained_models()\n",
        "\n",
        "## USE TEACHER MODELS TO CLASSIFY PRIVATE DATASET\n",
        "raw_teacher_labels = label_private_data(teacher_models, private_loader)\n",
        "condensed_labels = condense_teacher_labels(raw_teacher_labels)\n",
        "\n",
        "## ADD LAPLACIAN NOISE TO PREDICTIONS BY TEACHERS\n",
        "noised_teacher_labels = add_laplacian_noise(raw_teacher_labels, epsilon)\n",
        "\n",
        "## PERFORM PATE ANALYSIS TO CHECK PRIVACY LEAKAGE\n",
        "run_pate_analysis(noised_teacher_labels.T, condensed_labels, epsilon)\n",
        "\n",
        "## MODELING FOR STUDENT\n",
        "#student_model = \n",
        "#train_student_model = \n",
        "\n",
        "## VALIDATE ACCURACY OF STUDENT MODEL\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}