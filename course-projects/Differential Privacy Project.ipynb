{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Copy of Differential Privacy Project.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eazydammy/private-ai/blob/master/course-projects/Differential%20Privacy%20Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnKMy5hdXPKF",
        "colab_type": "code",
        "outputId": "a37226f4-27fe-4a77-acb7-a2253af20664",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# install PySyft if not available (e.g on cloud)\n",
        "!pip install syft\n",
        "\n",
        "# import required libraries\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Subset\n",
        "from torchvision import datasets, transforms\n",
        "from syft.frameworks.torch.differential_privacy import pate\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting syft\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/38/2e/16bdefc78eb089e1efa9704c33b8f76f035a30dc935bedd7cbb22f6dabaa/syft-0.1.21a1-py3-none-any.whl (219kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 2.8MB/s \n",
            "\u001b[?25hCollecting msgpack>=0.6.1 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/7e/ae9e91c1bb8d846efafd1f353476e3fd7309778b582d2fb4cea4cc15b9a2/msgpack-0.6.1-cp36-cp36m-manylinux1_x86_64.whl (248kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 56.1MB/s \n",
            "\u001b[?25hCollecting websocket-client>=0.56.0 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/19/44753eab1fdb50770ac69605527e8859468f3c0fd7dc5a76dd9c4dbd7906/websocket_client-0.56.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 58.7MB/s \n",
            "\u001b[?25hCollecting zstd>=1.4.0.0 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/37/6a7ba746ebddbd6cd06de84367515d6bc239acd94fb3e0b1c85788176ca2/zstd-1.4.1.0.tar.gz (454kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 52.6MB/s \n",
            "\u001b[?25hCollecting lz4>=2.1.6 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/c6/96bbb3525a63ebc53ea700cc7d37ab9045542d33b4d262d0f0408ad9bbf2/lz4-2.1.10-cp36-cp36m-manylinux1_x86_64.whl (385kB)\n",
            "\u001b[K     |████████████████████████████████| 389kB 47.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.21.2)\n",
            "Collecting tf-encrypted>=0.5.4 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/ff/7dbd5fc77fcec0df1798268a6b72a2ab0150b854761bc39c77d566798f0b/tf_encrypted-0.5.7-py3-none-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 43.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.3.0)\n",
            "Requirement already satisfied: Flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.16.4)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.0)\n",
            "Collecting flask-socketio>=3.3.2 (from syft)\n",
            "  Downloading https://files.pythonhosted.org/packages/4b/68/fe4806d3a0a5909d274367eb9b3b87262906c1515024f46c2443a36a0c82/Flask_SocketIO-4.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tblib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.4.0)\n",
            "Collecting websockets>=7.0 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/5e/2fe6afbb796c6ac5c006460b5503cd674d33706660337f2dbff10d4aa12d/websockets-8.0-cp36-cp36m-manylinux1_x86_64.whl (72kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 34.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from websocket-client>=0.56.0->syft) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (1.3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (0.13.2)\n",
            "Requirement already satisfied: tensorflow<2,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Collecting pyyaml>=5.1 (from tf-encrypted>=0.5.4->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/65/837fefac7475963d1eccf4aa684c23b95aa6c1d033a2c5965ccb11e22623/PyYAML-5.1.1.tar.gz (274kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 53.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->syft) (4.3.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (7.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (0.15.5)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (2.10.1)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (1.1.0)\n",
            "Collecting python-socketio>=2.1.0 (from flask-socketio>=3.3.2->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/1b/57e860a86f2a01be86ae1dacfa0cd8c4dfbfcd4593322268b61b5a07b564/python_socketio-4.2.0-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 25.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (3.7.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.33.4)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.7.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.1.7)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.11.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.0.8)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.2.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.8.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision>=0.3.0->syft) (0.46)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=1.0.2->syft) (1.1.1)\n",
            "Collecting python-engineio>=3.8.0 (from python-socketio>=2.1.0->flask-socketio>=3.3.2->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/b8/0fc389ca5c445051b37b17802f80bbf1b51c1e3b48b772ee608efbb90583/python_engineio-3.8.2.post1-py2.py3-none-any.whl (119kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 40.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (41.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (2.8.0)\n",
            "Building wheels for collected packages: zstd, pyyaml\n",
            "  Building wheel for zstd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/3f/ee/ac08c81af7c1b24a80c746df669ea3cb37542d27877d66ccf4\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/27/a1/775c62ddea7bfa62324fd1f65847ed31c55dadb6051481ba3f\n",
            "Successfully built zstd pyyaml\n",
            "Installing collected packages: msgpack, websocket-client, zstd, lz4, pyyaml, tf-encrypted, python-engineio, python-socketio, flask-socketio, websockets, syft\n",
            "  Found existing installation: msgpack 0.5.6\n",
            "    Uninstalling msgpack-0.5.6:\n",
            "      Successfully uninstalled msgpack-0.5.6\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed flask-socketio-4.1.0 lz4-2.1.10 msgpack-0.6.1 python-engineio-3.8.2.post1 python-socketio-4.2.0 pyyaml-5.1.1 syft-0.1.21a1 tf-encrypted-0.5.7 websocket-client-0.56.0 websockets-8.0 zstd-1.4.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0720 23:55:59.234785 140609652602752 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
            "W0720 23:55:59.251523 140609652602752 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZZYCM1OXPKJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "0abacfae-b476-4759-8d33-76b7797bb0ef"
      },
      "source": [
        "# import data set\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,))])\n",
        "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "#train_data = mnist_trainset.train_data\n",
        "#train_targets = mnist_trainset.train_labels\n",
        "\n",
        "#test_data = mnist_trainset.test_data\n",
        "#test_targets = mnist_trainset.test_labels\n",
        "\n",
        "train_data = mnist_trainset\n",
        "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "test_data = mnist_testset"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:01, 7007479.62it/s]                             \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 447385.15it/s]\n",
            "  1%|          | 16384/1648877 [00:00<00:11, 143656.10it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 7510016.52it/s]                           \n",
            "8192it [00:00, 180631.58it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNH218WkXPKN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define function to split training data into sub-datasets for a number of teachers\n",
        "# returns nt sub-datasets to train the each teacher model\n",
        "# TODO: split into train and test \n",
        "def split_train_data(train_data, num_teachers):\n",
        "    teacher_loaders = []\n",
        "    p, q = divmod(len(train_data), num_teachers)\n",
        "    #split_indices = list((train_data[i * p + min(i, q):(i + 1) * p + min(i + 1, q)] for i in range(num_teachers)))\n",
        "    split_indices = list(range((i * p + min(i, q)) , ((i + 1) * p + min(i+1, q))) for i in range(num_teachers))\n",
        "    for j in range(len(split_indices)):\n",
        "        subset_j = Subset(train_data, split_indices[j])\n",
        "        loader_j = torch.utils.data.DataLoader(subset_j, batch_size=64, shuffle=True)\n",
        "        teacher_loaders.append(loader_j)\n",
        "    return teacher_loaders"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEDk1ecqXPKP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define function to take a chunk of the test data as private dataset\n",
        "# returns reduced test data and private dataset in ratio: 0 < ratio < 1\n",
        "# to split reduced_test_data:private_data in 80:20, use ratio 0.8\n",
        "def split_test_data(test_data, ratio):    \n",
        "    divide = int(len(test_data) * ratio)\n",
        "    \n",
        "    reduced_indices = range(0, divide)\n",
        "    private_indices = range(divide, len(test_data))\n",
        "\n",
        "    reduced_subset = Subset(test_data, reduced_indices)\n",
        "    private_subset = Subset(test_data, private_indices)\n",
        "    \n",
        "    test_loader = torch.utils.data.DataLoader(reduced_subset, batch_size=64, shuffle=True)\n",
        "    private_loader = torch.utils.data.DataLoader(private_subset, batch_size=64, shuffle=True)\n",
        "    \n",
        "    return test_loader, private_loader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5JqrQyvXPKS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define class to build linear classifier models for each teacher\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_layers, drop_p=0.5):\n",
        "        ''' Builds a feedforward network with arbitrary hidden layers.\n",
        "        \n",
        "            Arguments\n",
        "            ---------\n",
        "            input_size: integer, size of the input layer\n",
        "            output_size: integer, size of the output layer\n",
        "            hidden_layers: list of integers, the sizes of the hidden layers\n",
        "        \n",
        "        '''\n",
        "        super().__init__()\n",
        "        # Input to a hidden layer\n",
        "        self.hidden_layers = nn.ModuleList([nn.Linear(input_size, hidden_layers[0])])\n",
        "        \n",
        "        # Add a variable number of more hidden layers\n",
        "        layer_sizes = zip(hidden_layers[:-1], hidden_layers[1:])\n",
        "        self.hidden_layers.extend([nn.Linear(h1, h2) for h1, h2 in layer_sizes])\n",
        "        self.output = nn.Linear(hidden_layers[-1], output_size)\n",
        "        self.dropout = nn.Dropout(p=drop_p)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        ''' Forward pass through the network, returns the output logits '''\n",
        "        \n",
        "        for each in self.hidden_layers:\n",
        "            x = F.relu(each(x))\n",
        "            x = self.dropout(x)\n",
        "        x = self.output(x)\n",
        "        \n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Nk2kApjXPKV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define function to train model given train and test datasets\n",
        "def train(model, trainloader, testloader, criterion, optimizer, epochs=5, print_every=50):\n",
        "    steps = 0\n",
        "    running_loss = 0\n",
        "    model.to(device)\n",
        "    for e in range(epochs):\n",
        "        model.train() # Model in training mode, grad & dropout is on\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            steps += 1\n",
        "            images.resize_(images.size()[0], 784)\n",
        "            optimizer.zero_grad()\n",
        "            output = model.forward(images)\n",
        "            loss = criterion(output, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            if steps % print_every == 0:\n",
        "                model.eval() # Model in evaluation mode, grad & dropout is off\n",
        "                with torch.no_grad():\n",
        "                    test_loss, accuracy = validation(model, testloader, criterion)\n",
        "                \n",
        "                print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
        "                      \"Training Loss: {:.3f}.. \".format(running_loss/print_every),\n",
        "                      \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
        "                      \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))\n",
        "                \n",
        "                running_loss = 0\n",
        "                model.train() # Model in training mode, grad & dropout is on"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeqGWMBuXPKX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define function to validate model using the reduced test data set\n",
        "def validation(model, testloader, criterion):\n",
        "    accuracy = 0\n",
        "    test_loss = 0\n",
        "    for images, labels in testloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        images = images.resize_(images.size()[0], 784)\n",
        "        output = model.forward(images)\n",
        "        test_loss += criterion(output, labels).item()\n",
        "        ## Calculating the accuracy \n",
        "        # Model's output is log-softmax, take exponential to get the probabilities\n",
        "        ps = torch.exp(output)\n",
        "        equality = (labels.data == ps.max(1)[1])\n",
        "        top_p, top_class = ps.topk(1, dim = 1)\n",
        "        equality = top_class == labels.view(*top_class.shape)\n",
        "        # Accuracy is number of correct predictions divided by all predictions, just take the mean\n",
        "        accuracy += equality.float().mean()\n",
        "    return test_loss, accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hw95IYoyXPKZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define function to build teacher models\n",
        "def build_teacher_models(num_teachers, teacher_dropout):\n",
        "    teacher_models = []\n",
        "    for i in range(num_teachers):\n",
        "        teacher_model = Classifier(784, 10, [512, 256, 128], drop_p = teacher_dropout)\n",
        "        teacher_models.append(teacher_model)\n",
        "    return teacher_models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjeCoaPOXPKc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define function to train teacher models\n",
        "def train_teacher_models(teacher_models, teacher_loaders, test_loader, teacher_criterion):\n",
        "    for i in range(len(teacher_models)):\n",
        "        print(\"Begin training Teacher\", i+1)\n",
        "        teacher_optimizer = optim.SGD(teacher_models[i].parameters(), lr=1e-3, momentum=0.9)\n",
        "        train(teacher_models[i], teacher_loaders[i], test_loader, teacher_criterion, teacher_optimizer, epochs=50)\n",
        "        print(\"Teacher\",i+1,\"trained successfully! \\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Q8ElPQbXPKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define function to perform PATE analysis\n",
        "def run_pate_analysis(noised_teacher_labels, raw_teacher_labels, epsilon):\n",
        "    data_dep_eps, data_ind_eps = pate.perform_analysis(teacher_preds=noised_teacher_labels, indices=raw_teacher_labels, noise_eps=epsilon, delta=1e-5)\n",
        "    print(\"Data Independent Epsilon:\", data_ind_eps)\n",
        "    print(\"Data Dependent Epsilon:\", data_dep_eps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8Fg0_wT5UJM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define function to save model training results\n",
        "def save_trained_models():\n",
        "  for i in range(len(teacher_models)): \n",
        "    torch.save(teacher_models[i].state_dict(), 'checkpoint%d.pth'%(i+1))\n",
        "    print(\"Saved model results for Teacher\", (i+1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mI4uRLvb5ot0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define function to load pre-trained models\n",
        "def load_trained_models():\n",
        "  for i in range(len(teacher_models)):\n",
        "    state_dict = torch.load('checkpoint%d.pth'%(i+1))\n",
        "    teacher_models[i].load_state_dict(state_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Afk0lIuR_s1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define function to classify private dataset\n",
        "def label_private_data(teacher_models, private_loader):\n",
        "  raw_teacher_labels = np.array([])\n",
        "  for i in range(len(teacher_models)): \n",
        "    teacher_models[i].to(device)\n",
        "    model_label = np.array([])#, dtype=np.int64).reshape(len(private_loader))\n",
        "    for images, _ in private_loader:\n",
        "        images = images.to(device)\n",
        "        images = images.resize_(images.size()[0], 784)\n",
        "        with torch.no_grad():\n",
        "          output = teacher_models[i].forward(images)\n",
        "          ps = torch.exp(output)\n",
        "        top_p, top_label = ps.topk(1, dim = 1)\n",
        "        top_label = top_label.to('cpu')\n",
        "        model_label = np.vstack((model_label, top_label)) if model_label.size else np.array(top_label)\n",
        "    #raw_teacher_labels.append(np.array(model_label))\n",
        "    raw_teacher_labels = np.hstack((raw_teacher_labels, model_label)) if raw_teacher_labels.size else np.array(model_label)\n",
        "  return raw_teacher_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLVSfvk6lyfA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define function to condense teacher labels for each image\n",
        "def condense_teacher_labels(teacher_labels):\n",
        "  condensed_labels = []\n",
        "  for teacher_label in teacher_labels:\n",
        "    label_count = np.bincount(teacher_label, minlength = 10)\n",
        "    condensed_label = np.argmax(label_count)\n",
        "    condensed_labels.append(condensed_label)\n",
        "  condensed_labels = np.array(condensed_labels)\n",
        "  return condensed_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZDoX-KBD01c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define function to add Laplacian noise scaled by epsilon value\n",
        "def add_laplacian_noise(raw_teacher_labels, epsilon):\n",
        "  noised_teacher_labels = []\n",
        "  beta = 1 / epsilon\n",
        "  for raw_teacher_label in raw_teacher_labels:\n",
        "    for i in range(len(raw_teacher_label)):\n",
        "      raw_teacher_label[i] += np.random.laplace(0, beta, 1)\n",
        "    noised_teacher_labels.append(raw_teacher_label)\n",
        "  noised_teacher_labels = np.array(noised_teacher_labels)\n",
        "  return noised_teacher_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8df1A7t2FSD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define function to create student model\n",
        "def create_student_model():\n",
        "  \n",
        "  return student_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zbm0pJ2WFZhX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define function to train student model\n",
        "#def train_student_model():\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wuf8UAMJFgR8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define function to validate student model\n",
        "def validate_student_model():\n",
        "  \n",
        "  return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEv-5P2UXPKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## DEFINE HYPERPARAMETERS\n",
        "num_teachers = 100\n",
        "teacher_dropout = 0.25\n",
        "teacher_criterion = nn.NLLLoss()\n",
        "epsilon = 0.1\n",
        "\n",
        "## CREATE DATALOADERS\n",
        "teacher_loaders = split_train_data(train_data, num_teachers)\n",
        "test_loader, private_loader = split_test_data(test_data, ratio=0.8)\n",
        "\n",
        "## MODELING FOR TEACHERS\n",
        "teacher_models = build_teacher_models(num_teachers, teacher_dropout)\n",
        "#train_teacher_models(teacher_models, teacher_loaders, test_loader, teacher_criterion)\n",
        "\n",
        "## SAVE TRAINING RESULTS FOR TEACHERS\n",
        "#save_trained_models()\n",
        "\n",
        "## USE TEACHER MODELS TO CLASSIFY PRIVATE DATASET\n",
        "raw_teacher_labels = label_private_data(teacher_models, private_loader)\n",
        "condensed_labels = condense_teacher_labels(raw_teacher_labels)\n",
        "\n",
        "## ADD LAPLACIAN NOISE TO PREDICTIONS BY TEACHERS\n",
        "noised_teacher_labels = add_laplacian_noise(raw_teacher_labels, epsilon)\n",
        "\n",
        "## PERFORM PATE ANALYSIS TO CHECK PRIVACY LEAKAGE\n",
        "run_pate_analysis(noised_teacher_labels.T, condensed_labels, epsilon)\n",
        "\n",
        "## MODELING FOR STUDENT\n",
        "#student_model = \n",
        "#train_student_model = \n",
        "\n",
        "## VALIDATE ACCURACY OF STUDENT MODEL\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIJdV9cGvysa",
        "colab_type": "code",
        "outputId": "0cf3d23f-9efa-443b-a390-7a4456bebc17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "run_pate_analysis(noised_teacher_labels.T, np.array(list(range(2000))), epsilon)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Independent Epsilon: 91.51292546497024\n",
            "Data Dependent Epsilon: 91.51292546497153\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIupjUGrwQ7s",
        "colab_type": "code",
        "outputId": "3c53c57b-cc15-456b-d8c5-457adab0a3b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "raw_teacher_labels = label_private_data(teacher_models, private_loader)\n",
        "raw_teacher_labels"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7, 8, 3, ..., 5, 6, 8],\n",
              "       [4, 3, 8, ..., 7, 6, 2],\n",
              "       [4, 3, 4, ..., 6, 6, 2],\n",
              "       ...,\n",
              "       [4, 3, 4, ..., 4, 6, 9],\n",
              "       [4, 3, 3, ..., 5, 6, 9],\n",
              "       [2, 3, 4, ..., 4, 6, 3]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaGSdvpSwtOm",
        "colab_type": "code",
        "outputId": "16b3e1b4-7687-4fd7-8313-748d3a04fa97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "noised_teacher_labels = add_laplacian_noise(raw_teacher_labels, epsilon)\n",
        "noised_teacher_labels"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-16,   0,  26, ...,  14,  16,  28],\n",
              "       [ 34,   3,  22, ...,   3,  -2,   6],\n",
              "       [  0,  -1,   1, ...,  12,  10,  -5],\n",
              "       ...,\n",
              "       [ 11,  43,   9, ...,   0,  -2,   3],\n",
              "       [  0,   1, -16, ...,   4,  36,  -8],\n",
              "       [  7,  15,   7, ...,   8,   6,  -8]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anzAHiGjw410",
        "colab_type": "code",
        "outputId": "ef06785a-62d3-4199-c58b-3c8cd8193fa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "run_pate_analysis(noised_teacher_labels.T, condensed_labels, epsilon)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Independent Epsilon: 91.51292546497024\n",
            "Data Dependent Epsilon: 91.51292546497153\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5V6RdzT2lme",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "50005fc0-613a-4f8f-cbed-3bdd39c0e9ea"
      },
      "source": [
        "raw_teacher_labels"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7, 8, 3, ..., 5, 6, 8],\n",
              "       [4, 3, 8, ..., 7, 6, 2],\n",
              "       [4, 3, 4, ..., 6, 6, 2],\n",
              "       ...,\n",
              "       [4, 3, 4, ..., 4, 6, 9],\n",
              "       [4, 3, 3, ..., 5, 6, 9],\n",
              "       [2, 3, 4, ..., 4, 6, 3]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVRa1Z_b1jXr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2eb09c07-645e-4e72-c8b0-68ea0d2c9468"
      },
      "source": [
        "condensed_labels = condense_teacher_labels(raw_teacher_labels)\n",
        "condensed_labels"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 2, 4, ..., 4, 5, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUXb5A2H2rFc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "9de76ee6-2ca3-4163-a4af-cf814c598706"
      },
      "source": [
        "noised_teacher_labels = add_laplacian_noise(raw_teacher_labels, epsilon)\n",
        "noised_teacher_labels"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  8, -25,  -9, ...,   0,  -5,  20],\n",
              "       [ 11,   3,  13, ...,   9,  14,   1],\n",
              "       [ 16,  15,  10, ...,   7,   7,  23],\n",
              "       ...,\n",
              "       [-29,  -1,  -9, ..., -21,   3,  11],\n",
              "       [ -9,   1,  22, ...,   3,  -1,   8],\n",
              "       [  8,  -1,   0, ...,   0,  -7, -18]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOfQeYzI24wj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "7c3f666d-d245-49cc-87bf-d80b89af33dd"
      },
      "source": [
        "condensed_noised_labels = condense_teacher_labels(noised_teacher_labels)\n",
        "condensed_noised_labels"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-61ede2640828>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcondensed_noised_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcondense_teacher_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoised_teacher_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcondensed_noised_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-a70e2b6a17a0>\u001b[0m in \u001b[0;36mcondense_teacher_labels\u001b[0;34m(teacher_labels)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mcondensed_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mteacher_label\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mteacher_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mlabel_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteacher_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mcondensed_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcondensed_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondensed_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: 'list' argument must have no negative elements"
          ]
        }
      ]
    }
  ]
}